{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Instructions: Panel Data Modeling with Machine Learning Models\n",
    "\n",
    "**Objective:**\n",
    "The goal of this exercise is to practice panel data modeling skills using three machine learning models (Random Forest, Single Decision Tree, and Linear Regression with Elastic Net) that have not been utilized in the project so far. Completing the entire task or a significant portion during the class will earn you an additional 7 points (above what is outlined in the syllabus) towards your final grade.\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "1. **GitHub Setup:**\n",
    "   - If you haven't done so already, [create](https://github.com/join) a GitHub account.\n",
    "   - [Download](https://desktop.github.com) and [configure](https://docs.github.com/en/desktop/configuring-and-customizing-github-desktop/configuring-basic-settings-in-github-desktop) GitHub Desktop on your laptop. (Here you can find nice intro to the GitHub Dekstop app: [link](https://joshuadull.github.io/GitHub-Desktop/02-getting-started/index.html)). If you prefare git command line usage you can go with this [instruction](https://github.com/michaelwozniak/ml2_tools?tab=readme-ov-file#git).\n",
    "2. **Repository Forking:**\n",
    "   - [Fork](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/working-with-forks/fork-a-repo) the following repository to your projects: [https://github.com/michaelwozniak/ML-in-Finance-I-case-study-forecasting-tax-avoidance-rates](https://github.com/michaelwozniak/ML-in-Finance-I-case-study-forecasting-tax-avoidance-rates)\n",
    "\n",
    "3. **Repository Cloning:**\n",
    "   - [Clone](https://docs.github.com/en/desktop/adding-and-cloning-repositories/cloning-a-repository-from-github-to-github-desktop) the forked repository to your local computer using GitHub Desktop.\n",
    "\n",
    "4. **Notebook Exploration:**\n",
    "   - Open the file `notebooks/10.exercise.ipynb` to begin the ML tasks.\n",
    "\n",
    "5. **Model Creation:**\n",
    "\n",
    "   In the file `notebooks/10.exercise.ipynb`:\n",
    "   - Create the following models:\n",
    "      1. Random Forest ([RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html))\n",
    "      2. Decision Tree ([DecisionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html))\n",
    "      3. Linear Regression with Elastic Net ([ElasticNet](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html))\n",
    "   \n",
    "   Follow a similar process to the models presented in class (e.g., KNN - `notebooks/07.knn-model.ipynb`):\n",
    "      - Load the prepared training data.\n",
    "      - Perform feature engineering if deemed necessary (note: these three models do not require data standardization, unlike SVM and KNN).\n",
    "      - Conduct feature selection.\n",
    "      - Perform hyperparameter tuning.\n",
    "      - Identify a local champion for each model class (the best model for RF, DT, Elastic Net).\n",
    "      - Save local champions to a pickle file.\n",
    "\n",
    "6. **Model Evaluation:**\n",
    "   - In the notebook `notebooks/09.final-comparison-and-summary.ipynb`, load the models you created and check if they outperform the previously used models.\n",
    "\n",
    "7. **Version Control:**\n",
    "   - At the end of the class, even if the tasks are incomplete, [commit](https://docs.github.com/en/desktop/making-changes-in-a-branch/committing-and-reviewing-changes-to-your-project-in-github-desktop) your changes using GitHub Desktop.\n",
    "   - [Push](https://docs.github.com/en/desktop/making-changes-in-a-branch/pushing-changes-to-github-from-github-desktop) your changes to your remote GitHub repository.\n",
    "\n",
    "8. **Submission:**\n",
    "   - Send me the link to your GitHub project (my email: *mj.wozniak9@uw.edu.pl*).\n",
    "\n",
    "Good luck with the exercise! If you have any questions, feel free to ask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# import data\n",
    "data_path = '/data/^IXIC.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Assuming the last column is the target variable\n",
    "X = data.iloc[:, :-1]  # Features\n",
    "y = data.iloc[:, -1]   # Target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# For illustration, selecting the top 10 features\n",
    "selector = SelectKBest(f_regression, k=10)\n",
    "X_selected = selector.fit_transform(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(RandomForestRegressor(random_state=42), param_grid_rf, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search_rf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "param_grid_dt = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 10, 20],\n",
    "}\n",
    "\n",
    "grid_search_dt = GridSearchCV(DecisionTreeRegressor(random_state=42), param_grid_dt, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search_dt.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "param_grid_en = {\n",
    "    'alpha': [0.1, 1.0, 10.0],\n",
    "    'l1_ratio': [0.1, 0.5, 0.9],\n",
    "}\n",
    "\n",
    "grid_search_en = GridSearchCV(ElasticNet(random_state=42), param_grid_en, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search_en.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the best models\n",
    "joblib.dump(grid_search_rf.best_estimator_, 'rf_best_model.pkl')\n",
    "joblib.dump(grid_search_dt.best_estimator_, 'dt_best_model.pkl')\n",
    "joblib.dump(grid_search_en.best_estimator_, 'elasticnet_best_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13 (main, Aug 25 2022, 18:24:45) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bff0f7c864331389fa2ce0c5d534e26d0bfdbc8f9c927a5938dc8a191fde6d96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
